#!/usr/bin/env python3

'''
Chess Engine Performance Data Collector

This script collects all JSON performance data files generated by the Chess Engine Performance Tests,
parses them, and organizes the data by app version and time frame
for later analysis and visualization
'''

import json
import os
import glob
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional
import re


@dataclass
class PerformanceData:
    '''Container for performance test data'''
    app_version: str
    timestamp: datetime
    test_group: str
    test_file: str
    results : List[Dict[str, Any]]
    file_path: str


@dataclass
class DataCollection:
    '''Main data collection container'''
    data_by_version : Dict[str, List[PerformanceData]] = field(default_factory=dict)
    data_by_timeframe : Dict[str, List[PerformanceData]] = field(default_factory=dict)
    all_data: List[PerformanceData] = field(default_factory=list)

    def add_data(self, perf_data: PerformanceData):
        '''Add performance data to the collection'''
        self.all_data.append(perf_data)

        # Group by version
        if perf_data.app_version not in self.data_by_version:
            self.data_by_version[perf_data.app_version]=[]
        self.data_by_version[perf_data.app_version].append(perf_data)

        # Groud by timeframe (daily)
        timeframe_key = perf_data.timestamp.strftime("%Y-%m-%d")
        if timeframe_key not in self.data_by_timeframe:
            self.data_by_timeframe[timeframe_key] = []
        self.data_by_timeframe[timeframe_key].append(perf_data)


class PerformanceDataCollector:
    '''Collects and organizes Chess Engine Performance data'''

    def __init__(self):
        '''Intitialize the data collector'''
        self.base_directory = os.path.join(os.getcwd(), "..", "build", "Chess.Engine.Performance", "Debug", "Performance_Results")  # adapt to config later
        self.collection = DataCollection()
        self.supported_test_types = ["move_generation", "positional_evaluation", "move_evaluation", "lightchessboard", "cpu_player", "cpu_performance"]

    def find_json_files(self) -> List[str]:
        '''Find all JSON performance result files'''
        search_patterns = [
            "**/Performance_Results/*.json",
            "**/CPU_VS_CPU_Results/*.json", 
            "**/*performance*.json",
            "**/*_performance_*.json"        
            ]
        
        json_files = []
        for pattern in search_patterns:
            files = glob.glob(os.path.join(self.base_directory, pattern), recursive=True)
            json_files.extend(files)

        # remove duplicates and sort
        return sorted(list(set(json_files)))
    
    def parse_json_file(self, file_path : str) -> Optional[PerformanceData]:
        '''Parse a single JSON performance file'''
        try:
            with open(file_path, 'r', encoding="utf-8") as f:
                data = json.load(f)

            # Extract meta data
            metadata = data.get('metadata', {})

            # Parse timestamp
            timestamp_str = metadata.get('timestamp','')
            timestamp = self._parse_timestamp(timestamp_str)

            # Extract version from results if available
            app_version = self._extract_version(data)
            
            # Create performance data object
            perf_data = PerformanceData(app_version=app_version, 
                                        timestamp=timestamp, 
                                        test_group=metadata.get('testGroup', 'Unkown'), 
                                        test_file=metadata.get('testFile', os.path.basename(file_path)),
                                        results=data.get('results', []), 
                                        file_path=file_path)

            return perf_data
        
        except Exception as ex:
            print(f'Error occurred during parsing: File path: {file_path}, Error: {ex}')
            return None


    def _parse_timestamp(self, timestamp_tr :str) -> datetime:
        '''Parse timestamp from various formats'''
        if not timestamp_tr:
            # Use file modification time as fallback
            return datetime.now()
        
        # Try mutliple timestamp formats
        formats = ["%Y-%m-%dT%H:%M:%SZ",  # ISO 8601 UTC
                   "%Y-%m-%dT%H:%M:%S",   # ISO 8601 local
                   "%Y%m%d_%H%M%S",       # Filename format
                   "%Y-%m-%d %H:%M:%S"    # Standard format
                   ]
        for fmt in formats:
            try:
                return datetime.strftime(timestamp_tr, fmt)
            except ValueError:
                continue

        # If no format works, try to extract from filename pattern
        return self._extract_timestamp_from_filename(timestamp_tr)


    def _extract_timestamp_from_filename(self, filename : str) -> datetime:
        '''Extract timestamp from filename if possible'''
        # Look for patterns like 20240830_213000
        pattern = r'(\d{8}_\d{6})'
        match = re.search(pattern, filename)
        if match:
            try:
                return datetime.strptime(match.group(1), "%Y%m%d_%H%M%S")
            except ValueError:
                pass

        return datetime.now()


    def _extract_version(self, data: Dict[str, Any]) -> str :
        '''Extract app version from JSON data'''
        # Check metadata first
        metadata = data.get('metadata', {})
        if 'version' in metadata:
            return metadata['version']
        
        # Check results for version info
        results = data.get('results', [])
        if results and isinstance(results, list) and len(results) > 0:
            first_result = results[0]
            if isinstance(first_result, dict):
                test_metadata = first_result.get('testMetadata', {})
                if 'version' in test_metadata:
                    return test_metadata['version']
                
        return "Unkown"


    def collect_all_data(self) -> DataCollection:
        '''Collect all performance data from JSON files'''
        json_files = self.find_json_files()
        
        print(f'Found {len(json_files)} JSON files to process...')

        processed_count = 0
        for file_path in json_files:
            perf_data = self.parse_json_file(file_path)
            if perf_data:
                self.collection.add_data(perf_data)
                processed_count += 1

        print(f'Successfully processed {processed_count} files')
        return self.collection


    def get_statistics(self) -> Dict[str, Any]:
        '''Get collection statistics'''
        stats = {
            'total_files': len(self.collection.all_data),
            'versions': list(self.collection.data_by_version.keys()),
            'version_counts': {v: len(data) for v, data in self.collection.data_by_version.items()},
            'date_range': self._get_date_range(),
            'test_groups': self._get_test_groups(),
            'total_test_results': sum(len(data.results) for data in self.collection.all_data)
        }

        return stats


    def _get_date_range(self) -> Dict[str, str]:
        '''Get the date range of collected data'''
        if not self.collection.all_data:
            return {'earliest' : 'N/A', 'latest':'N/A'}
        
        timestamps = [data.timestamp for data in self.collection.all_data]
        return {
            'earliest': min(timestamps).strftime("%Y-%m-%d %H:%M:%S"),
            'latest': max(timestamps).strftime("%Y-%m-%d %H:%M:%S")
        }


    def _get_test_groups(self) -> Dict[str, int]:
        '''Get count of test groups'''
        groups = {}
        for data in self.collection.all_data:
            group = data.test_group
            groups[group] = groups.get(group,0) + 1
        return groups


    def filter_by_version(self, version: str) -> List[PerformanceData]:
        '''Filter data by app version'''
        return self.collection.data_by_version.get(version,[])
    

    def filder_by_date_range(self, start_date: str, end_date: str) -> List[PerformanceData]:
        '''Filter data by date range (YYYY-MM-DD format)'''
        try:
            start = datetime.strptime(start_date, "%Y-%m-%d")
            end = datetime.strptime(end_date, "%Y-%m-%d")
            
            filtered_data = []
            for data in self.collect_all_data:
                if start <= data.timestamp <= end:
                    filtered_data.append(data)
            
            return filtered_data
        
        except ValueError as ex:
            print(f'Invalid date format: {ex}')
            return []


    def export_to_json(self, output_file: str = "collected_performance_data.json"):
        '''Export collected data to JSON file'''
        export_data = {
            'collection_timestamp':datetime.now().isoformat(),
            'statistics':self.get_statistics(),
            'data': []
        }
        
        for perf_data in self.collection.all_data:
            export_data['data'].append({
                'app_version': perf_data.app_version,
                'timestamp': perf_data.timestamp.isoformat(),
                'test_group': perf_data.test_group,
                'test_file': perf_data.test_file,
                'file_path': perf_data.file_path,
                'results': perf_data.results
            })

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

        print(f'Data exported to {output_file}')

